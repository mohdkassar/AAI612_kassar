{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h1>ARABIC DIALECT CLASSIFICATION</h1>\n",
        "<h5>MOHAMAD EL KASSAR</h5>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h3>Dataset Loading</h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "zhprTxLIzmO9"
      },
      "outputs": [],
      "source": [
        "file = open('workspace/deep-learning/AAI612_kassar/project2/data/IADD.json', 'r', encoding='utf-8')\n",
        "import json\n",
        "data = json.load(file)\n",
        "file.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "0QlBQKzT0YaL"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame(data)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h3>Dataset Analysis</h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 135804 entries, 0 to 135803\n",
            "Data columns (total 4 columns):\n",
            " #   Column      Non-Null Count   Dtype \n",
            "---  ------      --------------   ----- \n",
            " 0   Sentence    135804 non-null  object\n",
            " 1   Region      135804 non-null  object\n",
            " 2   DataSource  135804 non-null  object\n",
            " 3   Country     135804 non-null  object\n",
            "dtypes: object(4)\n",
            "memory usage: 4.1+ MB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Region</th>\n",
              "      <th>DataSource</th>\n",
              "      <th>Country</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>135804</td>\n",
              "      <td>135804</td>\n",
              "      <td>135804</td>\n",
              "      <td>135804</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>126389</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>اه</td>\n",
              "      <td>LEV</td>\n",
              "      <td>SHAMI</td>\n",
              "      <td>Syria</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>181</td>\n",
              "      <td>87573</td>\n",
              "      <td>66247</td>\n",
              "      <td>44972</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Sentence  Region DataSource Country\n",
              "count    135804  135804     135804  135804\n",
              "unique   126389       6          5      10\n",
              "top          اه     LEV      SHAMI   Syria\n",
              "freq        181   87573      66247   44972"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DataSource\n",
              "SHAMI    66247\n",
              "PADIC    36065\n",
              "AOC      19713\n",
              "TSAC     11998\n",
              "DART      1781\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['DataSource'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Country\n",
              "Syria        44972\n",
              "Palestine    17855\n",
              "NA           16441\n",
              "Algeria      14426\n",
              "Tunisia      11998\n",
              "Lebanon      10829\n",
              "Morocco       7213\n",
              "Jordan        7017\n",
              "Egypt         4837\n",
              "Iraq           216\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['Country'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Region\n",
              "LEV        87573\n",
              "MGH        33996\n",
              "GLF         6682\n",
              "EGY         4837\n",
              "general     2500\n",
              "IRQ          216\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['Region'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h3>Data Balancing Strategy</h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_1485/233559036.py:8: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda x: x.sample(min_count, random_state=42))\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Region\n",
              "EGY    2500\n",
              "GLF    2500\n",
              "LEV    2500\n",
              "MGH    2500\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_filtered = df[df['Region'] != 'IRQ']\n",
        "\n",
        "min_count = df_filtered['Region'].value_counts().min()\n",
        "\n",
        "balanced_df = (\n",
        "    df_filtered\n",
        "    .groupby('Region', group_keys=False)\n",
        "    .apply(lambda x: x.sample(min_count, random_state=42))\n",
        ")\n",
        "\n",
        "balanced_df = balanced_df[balanced_df['Region'] != 'general']\n",
        "\n",
        "balanced_df = balanced_df.reset_index(drop=True)\n",
        "\n",
        "balanced_df['Region'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_processed = balanced_df.copy()\n",
        "df_processed = df_processed[['Sentence', 'Region']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h3>Text Cleaning</h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hBe7TqLi0aOC",
        "outputId": "45fb0b77-f8dc-4db2-89e9-3a729e88705f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset size after preprocessing: (9918, 3)\n",
            "Dataset size after removing empty texts: (9918, 3)\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "def preprocess_arabic_text(text):\n",
        "\n",
        "    if pd.isna(text):\n",
        "        return \"\"\n",
        "\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "\n",
        "    text = re.sub(r'http[s]?://\\S+', '', text)\n",
        "\n",
        "    text = text.strip()\n",
        "\n",
        "    #remove non-Arabic characters\n",
        "    text = re.sub(r'[^\\u0600-\\u06FF\\s]', '', text)\n",
        "\n",
        "    #remove punctuation\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "\n",
        "    return text\n",
        "\n",
        "df_processed['processed_text'] = df_processed['Sentence'].apply(preprocess_arabic_text)\n",
        "\n",
        "print(\"Dataset size after preprocessing:\", df_processed.shape)\n",
        "\n",
        "#remove empty texts\n",
        "df_processed = df_processed[df_processed['processed_text'] != \"\"]\n",
        "\n",
        "print(\"Dataset size after removing empty texts:\", df_processed.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h3>Encoding the Region</h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AT6fVIzk0sxj",
        "outputId": "aee47e2b-3d3f-4e41-fe32-509ea3362c39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Encoded Regions:\n",
            " region_encoded\n",
            "0    2500\n",
            "1    2500\n",
            "2    2500\n",
            "3    2418\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Encoding region labels\n",
        "region_encoder = LabelEncoder()\n",
        "df_processed['region_encoded'] = region_encoder.fit_transform(df_processed['Region'])\n",
        "\n",
        "print(\"Encoded Regions:\\n\", df_processed['region_encoded'].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "</h3>Preparing Features and Labels</h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "KpgsaUb30xL9"
      },
      "outputs": [],
      "source": [
        "# prepare features and labels\n",
        "X = df_processed['processed_text'].tolist()\n",
        "y = df_processed['region_encoded'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "Ql-LC-Z-UENc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4\n"
          ]
        }
      ],
      "source": [
        "num_classes = len(region_encoder.classes_)\n",
        "print(num_classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h3>Train/Validation/Test Splitting</h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "yxLUbXL-0zS9"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_temp, X_test, y_temp, y_test = train_test_split(\n",
        "    X, y, test_size=0.15, random_state=42, stratify=y  # Smaller test set\n",
        ")\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_temp, y_temp, test_size=0.1, random_state=42, stratify=y_temp  # Smaller validation set\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afAt3L6eJp1-",
        "outputId": "25b4bb21-c1a9-4bf4-fb46-13e633f070a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "There are 7587 sentences for training.\n",
            "There are 843 sentences for validation.\n",
            "There are 1488 sentences for validation.\n"
          ]
        }
      ],
      "source": [
        "max_length = max([len(x) for x in X])\n",
        "MAXLEN = max_length\n",
        "\n",
        "print(f\"There are {len(X_train)} sentences for training.\")\n",
        "print(f\"There are {len(X_val)} sentences for validation.\")\n",
        "print(f\"There are {len(X_test)} sentences for validation.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Categorical Label Conversion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "NU82_FwSSo7q"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-07-28 06:42:18.450386: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-07-28 06:42:18.623985: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2025-07-28 06:42:19.265203: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2025-07-28 06:42:19.776005: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1753684940.229858    1485 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1753684940.355689    1485 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1753684941.540902    1485 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1753684941.541074    1485 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1753684941.541082    1485 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1753684941.541084    1485 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-07-28 06:42:21.659852: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y_train_cat = to_categorical(y_train, num_classes=num_classes)\n",
        "y_val_cat = to_categorical(y_val, num_classes=num_classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "zCJghCSuKc_j"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "def fit_tokenizer(train_sentences, num_words):\n",
        "\n",
        "    tokenizer = Tokenizer(num_words=num_words, oov_token='<OOV>')\n",
        "\n",
        "    tokenizer.fit_on_texts(train_sentences)\n",
        "\n",
        "    return tokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Due to computational constraints, vocabulary was limited"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eS2bScM5KpLg",
        "outputId": "39cabc5b-e38f-40f7-ebf3-0bb1c9d6e7a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocabulary contains 36957 words\n",
            "\n"
          ]
        }
      ],
      "source": [
        "NUM_WORDS = 1000\n",
        "\n",
        "tokenizer = fit_tokenizer(X_train, NUM_WORDS)\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "print(f\"Vocabulary contains {len(word_index)} words\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "UsPpfvOfLALM"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Sequence Padding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pXgVfWdjLIVQ",
        "outputId": "9c402a4d-d87c-41d4-9377-f5859f6817ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Padded training sequences have shape: (7587, 6400)\n",
            "\n",
            "Padded validation sequences have shape: (843, 6400)\n"
          ]
        }
      ],
      "source": [
        "PADDING = 'post'\n",
        "\n",
        "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
        "X_val_seq = tokenizer.texts_to_sequences(X_val)\n",
        "\n",
        "max_length = max(len(seq) for seq in X_train_seq + X_val_seq)\n",
        "\n",
        "train_padded_seq = pad_sequences(X_train_seq, maxlen=max_length, padding='post')\n",
        "val_padded_seq = pad_sequences(X_val_seq, maxlen=max_length, padding='post')\n",
        "\n",
        "print(f\"Padded training sequences have shape: {train_padded_seq.shape}\\n\")\n",
        "print(f\"Padded validation sequences have shape: {val_padded_seq.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h2>Model Architectures Implementation</h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "LSTM Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "z4O5OHp6Q6fo"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "from keras.optimizers import Adam\n",
        "from keras import Sequential\n",
        "\n",
        "def create_model(num_words, maxlen):\n",
        "\n",
        "    model = Sequential([\n",
        "        Embedding(input_dim=num_words, output_dim=128),\n",
        "        LSTM(128, dropout=0.2, recurrent_dropout=0.2, return_sequences=True),\n",
        "        LSTM(64, dropout=0.2, recurrent_dropout=0.2),  # Stacked LSTM\n",
        "        Dense(32, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    optimizer = Adam(learning_rate=0.001, clipnorm=1.0)\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy',optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "iq34Jck4RLoO",
        "outputId": "7e14bdcb-5645-484e-dc63-8949a075afc8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "NUM_EPOCHS = 10\n",
        "\n",
        "model = create_model(NUM_WORDS, MAXLEN)\n",
        "callback = EarlyStopping(monitor='loss', patience=2)\n",
        "\n",
        "history = model.fit(\n",
        "    train_padded_seq,\n",
        "    y_train_cat,\n",
        "    epochs=NUM_EPOCHS,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    validation_data=(val_padded_seq, y_val_cat),\n",
        "    callbacks=[callback],\n",
        "    verbose=1,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Fine-tuned BERT Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Base Model: bert-base-multilingual-cased"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification\n",
        "\n",
        "def create_fine_tuned_bert(num_classes, model_name='bert-base-multilingual-cased'):\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    model = TFAutoModelForSequenceClassification.from_pretrained(\n",
        "        model_name,\n",
        "        num_labels=num_classes\n",
        "    )\n",
        "    \n",
        "    model.compile(\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    \n",
        "    model.summary()\n",
        "\n",
        "    return model, tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def prepare_bert_data(texts, labels, tokenizer, max_length=512):\n",
        "    encoded = tokenizer(\n",
        "        texts,\n",
        "        truncation=True,\n",
        "        padding=True,\n",
        "        max_length=max_length,\n",
        "        return_tensors='tf'\n",
        "    )\n",
        "    \n",
        "    return {\n",
        "        'input_ids': encoded['input_ids'],\n",
        "        'attention_mask': encoded['attention_mask']\n",
        "    }, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_bert_model(model, train_data, train_labels, val_data, val_labels, \n",
        "                     batch_size=16, epochs=3):\n",
        "    \n",
        "    history = model.fit(\n",
        "        train_data,\n",
        "        train_labels,\n",
        "        epochs=epochs,\n",
        "        batch_size=batch_size,\n",
        "        validation_data=(val_data, val_labels),\n",
        "        verbose=1\n",
        "    )\n",
        "    \n",
        "    return history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-07-27 20:01:01.051149: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n",
            "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"tf_bert_for_sequence_classification\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bert (TFBertMainLayer)      multiple                  177853440 \n",
            "                                                                 \n",
            " dropout_37 (Dropout)        multiple                  0 (unused)\n",
            "                                                                 \n",
            " classifier (Dense)          multiple                  3076      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 177856516 (678.47 MB)\n",
            "Trainable params: 177856516 (678.47 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/3\n",
            "  2/475 [..............................] - ETA: 2:24:12 - loss: 4.6042 - accuracy: 0.2188"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
            "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
            "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mCanceled future for execute_request message before replies were done"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mCanceled future for execute_request message before replies were done. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "model, tokenizer = create_fine_tuned_bert(num_classes)\n",
        "\n",
        "train_bert_data, y_train_bert = prepare_bert_data(\n",
        "    X_train, y_train_cat, tokenizer, max_length=256\n",
        ")\n",
        "\n",
        "val_bert_data, y_val_bert = prepare_bert_data(\n",
        "    X_val, y_val_cat, tokenizer, max_length=256\n",
        ")\n",
        "\n",
        "history = train_bert_model(\n",
        "    model, \n",
        "    train_bert_data, y_train_bert,\n",
        "    val_bert_data, y_val_bert,\n",
        "    batch_size=16,\n",
        "    epochs=3\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "47/47 [==============================] - 184s 4s/step\n"
          ]
        }
      ],
      "source": [
        "y_test_cat = to_categorical(y_test, num_classes=num_classes)\n",
        "\n",
        "test_bert_data, y_test_bert = prepare_bert_data(\n",
        "    X_test, y_test_cat, tokenizer, max_length=128\n",
        ")\n",
        "\n",
        "predictions = model.predict(test_bert_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "y_pred = np.argmax(predictions[0], axis=1)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
