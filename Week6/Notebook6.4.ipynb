{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# AAI612: Deep Learning & its Applications\n",
    "\n",
    "*Notebook 6.4: How do you feel about that movie?*\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/harmanani/AAI612/blob/main/Week6/Notebook6.4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I went and saw this movie last night after bei...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Actor turned director Bill Paxton follows up h...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>As a recreational golfer with some knowledge o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  I went and saw this movie last night after bei...          1\n",
       "1  Actor turned director Bill Paxton follows up h...          1\n",
       "2  As a recreational golfer with some knowledge o...          1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ssl\n",
    "\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/harmanani/AAI612/main/Week6/data/movie_data.csv', encoding='utf-8')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df.loc[:24999, 'review'].values\n",
    "y_train = df.loc[:24999, 'sentiment'].values\n",
    "X_test = df.loc[25000:, 'review'].values\n",
    "y_test = df.loc[25000:, 'sentiment'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.concatenate((X_train, X_test), axis=0)\n",
    "y = np.concatenate((y_train, y_test), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: \n",
      "(50000,)\n",
      "(50000,)\n"
     ]
    }
   ],
   "source": [
    "# summarize size\n",
    "print(\"Training data: \")\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "tokenizer_obj = Tokenizer()\n",
    "total_reviews = X_train + X_test\n",
    "tokenizer_obj.fit_on_texts(total_reviews) \n",
    "\n",
    "# pad sequences\n",
    "max_length = 100 # try other options like mean\n",
    "\n",
    "# define vocabulary size\n",
    "vocab_size = len(tokenizer_obj.word_index) + 1\n",
    "\n",
    "X_train_tokens =  tokenizer_obj.texts_to_sequences(X_train)\n",
    "X_test_tokens = tokenizer_obj.texts_to_sequences(X_test)\n",
    "\n",
    "\n",
    "X_train_pad = pad_sequences(X_train_tokens, maxlen=max_length, padding='post')\n",
    "X_test_pad = pad_sequences(X_test_tokens, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125602\n"
     ]
    }
   ],
   "source": [
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "Summary of the built model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n",
      "2025-07-12 06:28:32.151450: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                       │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru (\u001b[38;5;33mGRU\u001b[0m)                       │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, GRU\n",
    "from tensorflow.keras.layers import Embedding\n",
    "\n",
    "EMBEDDING_DIM = 100\n",
    "\n",
    "print('Build model...')\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, EMBEDDING_DIM, input_length=max_length))\n",
    "model.add(GRU(units=32,  dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "print('Summary of the built model...')\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Epoch 1/25\n",
      "196/196 - 40s - 202ms/step - accuracy: 0.6851 - loss: 0.5762 - val_accuracy: 0.7844 - val_loss: 0.4719\n",
      "Epoch 2/25\n",
      "196/196 - 34s - 176ms/step - accuracy: 0.8521 - loss: 0.3608 - val_accuracy: 0.8335 - val_loss: 0.3814\n",
      "Epoch 3/25\n",
      "196/196 - 35s - 177ms/step - accuracy: 0.9129 - loss: 0.2318 - val_accuracy: 0.8356 - val_loss: 0.3981\n",
      "Epoch 4/25\n",
      "196/196 - 35s - 177ms/step - accuracy: 0.9489 - loss: 0.1457 - val_accuracy: 0.8297 - val_loss: 0.4381\n",
      "Epoch 5/25\n",
      "196/196 - 34s - 176ms/step - accuracy: 0.9713 - loss: 0.0886 - val_accuracy: 0.8245 - val_loss: 0.5268\n",
      "Epoch 6/25\n",
      "196/196 - 36s - 183ms/step - accuracy: 0.9847 - loss: 0.0481 - val_accuracy: 0.8208 - val_loss: 0.6036\n",
      "Epoch 7/25\n",
      "196/196 - 37s - 187ms/step - accuracy: 0.9928 - loss: 0.0262 - val_accuracy: 0.8190 - val_loss: 0.6951\n",
      "Epoch 8/25\n",
      "196/196 - 36s - 184ms/step - accuracy: 0.9950 - loss: 0.0167 - val_accuracy: 0.8149 - val_loss: 0.7616\n",
      "Epoch 9/25\n",
      "196/196 - 34s - 176ms/step - accuracy: 0.9973 - loss: 0.0093 - val_accuracy: 0.8104 - val_loss: 0.8326\n",
      "Epoch 10/25\n",
      "196/196 - 35s - 176ms/step - accuracy: 0.9989 - loss: 0.0050 - val_accuracy: 0.8081 - val_loss: 0.9101\n",
      "Epoch 11/25\n",
      "196/196 - 35s - 177ms/step - accuracy: 0.9986 - loss: 0.0046 - val_accuracy: 0.8074 - val_loss: 0.9508\n",
      "Epoch 12/25\n",
      "196/196 - 35s - 178ms/step - accuracy: 0.9994 - loss: 0.0032 - val_accuracy: 0.8024 - val_loss: 0.9854\n",
      "Epoch 13/25\n",
      "196/196 - 35s - 177ms/step - accuracy: 0.9993 - loss: 0.0033 - val_accuracy: 0.8051 - val_loss: 1.0323\n",
      "Epoch 14/25\n",
      "196/196 - 35s - 177ms/step - accuracy: 0.9991 - loss: 0.0035 - val_accuracy: 0.8006 - val_loss: 1.1006\n",
      "Epoch 15/25\n",
      "196/196 - 38s - 195ms/step - accuracy: 0.9990 - loss: 0.0030 - val_accuracy: 0.7992 - val_loss: 1.0950\n",
      "Epoch 16/25\n",
      "196/196 - 36s - 184ms/step - accuracy: 0.9992 - loss: 0.0024 - val_accuracy: 0.7976 - val_loss: 1.1424\n",
      "Epoch 17/25\n",
      "196/196 - 37s - 188ms/step - accuracy: 0.9994 - loss: 0.0023 - val_accuracy: 0.7975 - val_loss: 1.1763\n",
      "Epoch 18/25\n",
      "196/196 - 36s - 186ms/step - accuracy: 0.9996 - loss: 0.0016 - val_accuracy: 0.7982 - val_loss: 1.2317\n",
      "Epoch 19/25\n",
      "196/196 - 38s - 191ms/step - accuracy: 0.9994 - loss: 0.0013 - val_accuracy: 0.7965 - val_loss: 1.3005\n",
      "Epoch 20/25\n",
      "196/196 - 39s - 200ms/step - accuracy: 0.9996 - loss: 0.0012 - val_accuracy: 0.7978 - val_loss: 1.3002\n",
      "Epoch 21/25\n",
      "196/196 - 39s - 200ms/step - accuracy: 0.9997 - loss: 9.7675e-04 - val_accuracy: 0.7925 - val_loss: 1.2804\n",
      "Epoch 22/25\n",
      "196/196 - 42s - 215ms/step - accuracy: 0.9999 - loss: 7.4137e-04 - val_accuracy: 0.7964 - val_loss: 1.3149\n",
      "Epoch 23/25\n",
      "196/196 - 43s - 221ms/step - accuracy: 0.9999 - loss: 4.5378e-04 - val_accuracy: 0.7949 - val_loss: 1.3830\n",
      "Epoch 24/25\n",
      "196/196 - 42s - 212ms/step - accuracy: 0.9999 - loss: 4.7978e-04 - val_accuracy: 0.7956 - val_loss: 1.4755\n",
      "Epoch 25/25\n",
      "196/196 - 44s - 226ms/step - accuracy: 0.9996 - loss: 0.0011 - val_accuracy: 0.7904 - val_loss: 1.3685\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f41fc1b5c90>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Train...')\n",
    "\n",
    "model.fit(X_train_pad, y_train, batch_size=128, epochs=25, validation_data=(X_test_pad, y_test), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing...\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 35ms/step - accuracy: 0.7493 - loss: 1.6692\n",
      "Test score: 1.3684719800949097\n",
      "Test accuracy: 0.7903599739074707\n",
      "Accuracy: 79.04%\n"
     ]
    }
   ],
   "source": [
    "print('Testing...')\n",
    "score, acc = model.evaluate(X_test_pad, y_test, batch_size=128)\n",
    "\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)\n",
    "\n",
    "print(\"Accuracy: {0:.2%}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 543ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[9.9962837e-01],\n",
       "       [8.8705337e-01],\n",
       "       [8.5703921e-01],\n",
       "       [2.8630244e-04],\n",
       "       [4.5266222e-02],\n",
       "       [1.1997067e-01],\n",
       "       [7.7446914e-01],\n",
       "       [2.0309440e-04]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let us test some  samples\n",
    "test_sample_1 = \"This movie is fantastic! I really like it because it is so good!\"\n",
    "test_sample_2 = \"Good movie!\"\n",
    "test_sample_3 = \"Maybe I like this movie.\"\n",
    "test_sample_4 = \"Not to my taste, will skip and watch another movie\"\n",
    "test_sample_5 = \"if you like action, then this movie might be good for you.\"\n",
    "test_sample_6 = \"Bad movie!\"\n",
    "test_sample_7 = \"Not a good movie!\"\n",
    "test_sample_8 = \"This movie really sucks! Can I get my money back please?\"\n",
    "test_samples = [test_sample_1, test_sample_2, test_sample_3, test_sample_4, test_sample_5, test_sample_6, test_sample_7, test_sample_8]\n",
    "\n",
    "test_samples_tokens = tokenizer_obj.texts_to_sequences(test_samples)\n",
    "test_samples_tokens_pad = pad_sequences(test_samples_tokens, maxlen=max_length)\n",
    "\n",
    "#predict\n",
    "model.predict(x=test_samples_tokens_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 525ms/step\n",
      "[0.0004154] 1  Wrong prdiction\n",
      "[0.0001244] 1  Wrong prdiction\n",
      "[0.03361538] 1  Wrong prdiction\n",
      "[0.06252406] 1  Wrong prdiction\n",
      "[0.9998524] 1  Right prdiction\n",
      "[0.9994927] 1  Right prdiction\n",
      "[0.99995434] 1  Right prdiction\n",
      "[5.123401e-07] 1  Wrong prdiction\n",
      "[0.00582552] 1  Wrong prdiction\n",
      "[0.99998116] 1  Right prdiction\n"
     ]
    }
   ],
   "source": [
    "#let us check how the model predicts\n",
    "classes = model.predict(X_test_pad[:10], batch_size=128)\n",
    "for i in range (0,10):\n",
    "    if(classes[i] > 0.5 and y_test[i] == 1 or (classes[i] <= 0.5 and y_test[i] == 0)):\n",
    "        print( classes[i], y_test[i], \" Right prdiction\")\n",
    "    else :\n",
    "        print( classes[i], y_test[i], \" Wrong prdiction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "\u001b[1m17464789/17464789\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step \n",
      "Build model...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing import sequence\n",
    "from keras.layers import Dense, Embedding, LSTM, GRU\n",
    "from tensorflow.keras.layers import Embedding\n",
    "\n",
    "# load the dataset but only keep the top n words, zero the rest\n",
    "top_words = 5000\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=top_words)\n",
    "\n",
    "max_words = 500\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_words)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_words)\n",
    "\n",
    "print('Build model...')\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(top_words, 100, input_length=max_words))\n",
    "model.add(LSTM(32, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Epoch 1/25\n",
      "196/196 - 123s - 626ms/step - accuracy: 0.7418 - loss: 0.5201 - val_accuracy: 0.8230 - val_loss: 0.4039\n",
      "Epoch 2/25\n",
      "196/196 - 120s - 610ms/step - accuracy: 0.8183 - loss: 0.4106 - val_accuracy: 0.7210 - val_loss: 0.5443\n",
      "Epoch 3/25\n",
      "196/196 - 113s - 578ms/step - accuracy: 0.8100 - loss: 0.4181 - val_accuracy: 0.8390 - val_loss: 0.3774\n",
      "Epoch 4/25\n",
      "196/196 - 111s - 564ms/step - accuracy: 0.8566 - loss: 0.3438 - val_accuracy: 0.8326 - val_loss: 0.3865\n",
      "Epoch 5/25\n",
      "196/196 - 115s - 586ms/step - accuracy: 0.8676 - loss: 0.3244 - val_accuracy: 0.8392 - val_loss: 0.3773\n",
      "Epoch 6/25\n",
      "196/196 - 144s - 733ms/step - accuracy: 0.8727 - loss: 0.3095 - val_accuracy: 0.8506 - val_loss: 0.3639\n",
      "Epoch 7/25\n",
      "196/196 - 117s - 595ms/step - accuracy: 0.8858 - loss: 0.2846 - val_accuracy: 0.8483 - val_loss: 0.3713\n",
      "Epoch 8/25\n",
      "196/196 - 90s - 461ms/step - accuracy: 0.8872 - loss: 0.2817 - val_accuracy: 0.8504 - val_loss: 0.3698\n",
      "Epoch 9/25\n",
      "196/196 - 88s - 449ms/step - accuracy: 0.8853 - loss: 0.2858 - val_accuracy: 0.8483 - val_loss: 0.3815\n",
      "Epoch 10/25\n",
      "196/196 - 90s - 459ms/step - accuracy: 0.8986 - loss: 0.2570 - val_accuracy: 0.8538 - val_loss: 0.3654\n",
      "Epoch 11/25\n",
      "196/196 - 115s - 585ms/step - accuracy: 0.8934 - loss: 0.2696 - val_accuracy: 0.8496 - val_loss: 0.3724\n",
      "Epoch 12/25\n",
      "196/196 - 101s - 513ms/step - accuracy: 0.9037 - loss: 0.2452 - val_accuracy: 0.8484 - val_loss: 0.3810\n",
      "Epoch 13/25\n",
      "196/196 - 94s - 481ms/step - accuracy: 0.9074 - loss: 0.2349 - val_accuracy: 0.8451 - val_loss: 0.3951\n",
      "Epoch 14/25\n",
      "196/196 - 92s - 471ms/step - accuracy: 0.9150 - loss: 0.2175 - val_accuracy: 0.8562 - val_loss: 0.3804\n",
      "Epoch 15/25\n",
      "196/196 - 92s - 472ms/step - accuracy: 0.9190 - loss: 0.2058 - val_accuracy: 0.8552 - val_loss: 0.4034\n",
      "Epoch 16/25\n",
      "196/196 - 92s - 471ms/step - accuracy: 0.9250 - loss: 0.1929 - val_accuracy: 0.8571 - val_loss: 0.3963\n",
      "Epoch 17/25\n",
      "196/196 - 92s - 471ms/step - accuracy: 0.9286 - loss: 0.1846 - val_accuracy: 0.8508 - val_loss: 0.4172\n",
      "Epoch 18/25\n",
      "196/196 - 93s - 473ms/step - accuracy: 0.9289 - loss: 0.1843 - val_accuracy: 0.8440 - val_loss: 0.4434\n",
      "Epoch 19/25\n",
      "196/196 - 105s - 538ms/step - accuracy: 0.9347 - loss: 0.1683 - val_accuracy: 0.8498 - val_loss: 0.4213\n",
      "Epoch 20/25\n",
      "196/196 - 113s - 578ms/step - accuracy: 0.9376 - loss: 0.1624 - val_accuracy: 0.8437 - val_loss: 0.4555\n",
      "Epoch 21/25\n",
      "196/196 - 112s - 572ms/step - accuracy: 0.9441 - loss: 0.1495 - val_accuracy: 0.8482 - val_loss: 0.4642\n",
      "Epoch 22/25\n",
      "196/196 - 110s - 563ms/step - accuracy: 0.9468 - loss: 0.1422 - val_accuracy: 0.8527 - val_loss: 0.4578\n",
      "Epoch 23/25\n",
      "196/196 - 112s - 571ms/step - accuracy: 0.9471 - loss: 0.1400 - val_accuracy: 0.8474 - val_loss: 0.4801\n",
      "Epoch 24/25\n",
      "196/196 - 156s - 798ms/step - accuracy: 0.9465 - loss: 0.1433 - val_accuracy: 0.8491 - val_loss: 0.4825\n",
      "Epoch 25/25\n",
      "196/196 - 110s - 563ms/step - accuracy: 0.9530 - loss: 0.1264 - val_accuracy: 0.8494 - val_loss: 0.4958\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f41547cb950>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Train...')\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=128, epochs=25, validation_data=(X_test, y_test), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 95ms/step - accuracy: 0.8465 - loss: 0.5089 \n",
      "Test score: 0.495782732963562\n",
      "Test accuracy: 0.849399983882904\n",
      "Accuracy: 84.94%\n"
     ]
    }
   ],
   "source": [
    "score, acc = model.evaluate(X_test, y_test, batch_size=128)\n",
    "\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)\n",
    "print(\"Accuracy: %.2f%%\" % (acc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The time to train a GRU is less than LSTM network."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
